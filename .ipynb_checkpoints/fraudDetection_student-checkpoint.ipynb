{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: fraud detection through ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/fraud.jpg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will use all the skills in ensemble learning we acquired from previous exercises to build a an automated fraud detection system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed. Both correctness of the solution and code quality will be taken into account for marking.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is an advanced and voluntary excercise that can help you gain a deeper knowledge into the topic. This exercise won't be taken into account towards marking, but you are encouraged to undertake it. Good luck!</td></tr>\n",
    "</table>\n",
    "\n",
    "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Ensembles environment files](https://github.com/albarji/teaching-environments-ensembles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Shift+Tab to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this problem is included in the *data* folder, with separate files for training and test data. Each file includes several unidentified explanatory features, together with an \"Amount\" feature and the target \"Class\". Fraudulent operations are marked as Class == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Load the training and test data into Pandas DataFrames with names <b>train</b> and <b>test</b>, respectively.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "1 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "2 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "3 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "4  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
       "1 -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966 -0.293803   \n",
       "2 -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
       "3 -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207 -0.053502   \n",
       "4 -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805 -1.632653   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/fraud_train.csv\", sep = ',')\n",
    "test = pd.read_csv (\"./data/fraud_test.csv\", sep = ',')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Perform a brief analysis of the training data to answer the following questions: how many explanatory variables do you have? What is the distribution of classes?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dimension: (5246, 30)\n",
      "test dimension: (5246, 30)\n",
      "number of explanatory variables: 29\n",
      "number of fraudulent operations: 246\n",
      "number of not fraudulent operations: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"train dimension:\" ,train.shape)\n",
    "print(\"test dimension:\" ,test.shape)\n",
    "X_train, y_train = train.drop([\"Class\"], axis=1), train[\"Class\"]\n",
    "X_test, y_test = test.drop([\"Class\"], axis=1), test[\"Class\"]\n",
    "print(\"number of explanatory variables:\", X_train.shape[1])\n",
    "print(\"number of fraudulent operations:\" , len(y_train[y_train==1]))\n",
    "print(\"number of not fraudulent operations:\", len(y_train[y_train==0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the performance of a fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraudulent activities are usually prosecuted, therefore fraudsters need to be creative and come up constantly with new ways of performing fraud. Furthermore, frauds are scarce (fortunately), and so we have few positive class patterns available for training. This means the problem is highly unbalanced, which is a problem for training good models, but is also a problem for the model evaluation. \n",
    "\n",
    "Consider a dumb model that classifies all data as negative (non-fraud). We can simulate the predictions of this model by creating a predictions vector of all zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumbpreds = [0] * len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the accuracy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531071292413267"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test[\"Class\"], dumbpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yo should have obtained a 95% of accuracy, because most of the patterns are indeed negative. But this would be totally useless as a fraud detector! Therefore, we need a better metric.\n",
    "\n",
    "One that works well for heavily unbalanced problems is the [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic), or AUC in short. In scikit-learn this metric is readily available, and we can test how this reveals the poor performance of this dumb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(test[\"Class\"], dumbpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AUC of 50% means the model is no better than a random guess. We should aim to maximize this metric and attain a 100%, meaning all fraudulent patterns obtain higher scores than non-fraud patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now we have scarce positive data, it might make sense to start building an unsupervised fraud detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Using <b>only the training data</b>, create an Isolation Forest model for anomaly detection. You can use the number of positive patterns in the data to adjust the contamination ratio. Then measure the performance of the model on the test set, in terms of AUC score.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Note the roc_auc_score metric must receive <b>positive class probabilities</b>. It is not possible to obtain these probabilities from an IsolationForest model, but you can make use of its decision_function method to obtain normality scores (average tree depth), which can be negated to obtain positive class scores.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.04689287075867327)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_detection = IsolationForest(contamination=len(y_train[y_train==1])/len(y_train))\n",
    "anomaly_detection.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of anomalies or fraud in test: 246\n",
      "number of no anomalies or no fraud in test: 5000\n",
      "number of good predictions of fraud in test: 152\n"
     ]
    }
   ],
   "source": [
    "preds = anomaly_detection.predict(X_test)\n",
    "idx_anomalies = np.where(preds == -1)\n",
    "\n",
    "print(\"number of anomalies or fraud in test:\" ,len(y_test[y_test==1]))\n",
    "print(\"number of no anomalies or no fraud in test:\" ,len(y_test[y_test==0]))\n",
    "print(\"number of good predictions of fraud in test:\" ,sum(y_test[idx_anomalies[0]]==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374105691056911"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decision_function = anomaly_detection.decision_function(X_test)\n",
    "len(test_decision_function[test_decision_function<0])\n",
    "roc_auc_score(y_test,-test_decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Create a visualization showing the performance of this model over the test data. Suggestion: make use of the <a href=https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html>ROC plot portrayed in the scikit-learn docs</a>\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374105691056911"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, -test_decision_function)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Let's check now whether we can improve the results using supervised models, that is, models that exploit the Class information available in the training data. Try <b>at least five</b> ensemble-based classification models, <b>using only the data in the training set</b>.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Some suggestions on the scikit-learn models you can use are: Random Forest, Extra Trees, AdaBoost, Gradient Boosting, Bagging, Voting and Stacking. You can also use an XGBClassifier, also included in this environment.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "     Bonus points will we awarded for:\n",
    "     <ul>\n",
    "         <li>Trying more ensemble strategies beyond the minimum requirement of five.</li>\n",
    "         <li>Improving the AUC score of your best model as much as possible.</li>\n",
    "         <li>Trying <a href=https://catboost.ai/>CatBoost</a> and/or <a href=https://lightgbm.readthedocs.io/en/latest/>LightGBM</a>, other two popular ensemble methods. Note you will need to install these in your environment.</li>\n",
    "     </ul>\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.984369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.976935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.992185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xt</th>\n",
       "      <td>0.991041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.988753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "sgd  0.984369\n",
       "dt   0.976935\n",
       "rf   0.992185\n",
       "xt   0.991041\n",
       "gb   0.988753"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "X_train, y_train = train.iloc[:,:len(train.columns)-1], train.iloc[:, len(train.columns)-1]\n",
    "X_test, y_test = test.iloc[:,:len(test.columns)-1], test.iloc[:, len(test.columns)-1]\n",
    "\n",
    "base_learners = [    \n",
    "    ('sgd', SGDClassifier()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('xt', ExtraTreesClassifier()),    \n",
    "    ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "d = {     \n",
    "    mod_name: mod_obj.fit(X_train, y_train).score(X_test, y_test) \n",
    "     for mod_name, mod_obj in base_learners\n",
    "}\n",
    "\n",
    "base_scores = pd.DataFrame.from_dict(data = d, orient='index')\n",
    "base_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.984947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.831186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.995933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xt</th>\n",
       "      <td>0.995638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.952644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "sgd  0.984947\n",
       "dt   0.831186\n",
       "rf   0.995933\n",
       "xt   0.995638\n",
       "gb   0.952644"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_scores = {}\n",
    "for mod_name, mod_obj in base_learners:\n",
    "    mod_obj.fit(X_train, y_train)\n",
    "    preds = mod_obj.predict(X_test)\n",
    "    score = roc_auc_score(preds, y_test)\n",
    "    roc_auc_scores[mod_name] = score\n",
    "    \n",
    "base_roc_auc_scores = pd.DataFrame.from_dict(data = roc_auc_scores, orient='index')\n",
    "base_roc_auc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.989897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.991231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.992185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xt</th>\n",
       "      <td>0.990660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.991803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "sgd  0.989897\n",
       "dt   0.991231\n",
       "rf   0.992185\n",
       "xt   0.990660\n",
       "gb   0.991803"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "ESTIMS = 50\n",
    "\n",
    "bagging_data = {mod_name: \n",
    "                BaggingClassifier(base_estimator=mod_obj, n_estimators=ESTIMS, n_jobs=-1)\n",
    "                .fit(X_train, y_train)\n",
    "                .score(X_test, y_test)    \n",
    "    for mod_name, mod_obj in base_learners\n",
    "}\n",
    "\n",
    "bagging_scores = pd.DataFrame.from_dict(data=bagging_data, orient='index')\n",
    "bagging_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.987236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.982041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.995933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xt</th>\n",
       "      <td>0.995246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.986361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "sgd  0.987236\n",
       "dt   0.982041\n",
       "rf   0.995933\n",
       "xt   0.995246\n",
       "gb   0.986361"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_roc_auc_data = {}\n",
    "for mod_name, mod_obj in base_learners:\n",
    "    bagging_model = BaggingClassifier(base_estimator=mod_obj, n_estimators=ESTIMS, n_jobs=-1)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    preds = bagging_model.predict(X_test)\n",
    "    score = roc_auc_score(preds, y_test)\n",
    "    bagging_roc_auc_data[mod_name] = score\n",
    "    \n",
    "bagging_roc_auc_scores = pd.DataFrame.from_dict(data = bagging_roc_auc_data, orient='index')\n",
    "bagging_roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.988563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.974647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.991994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xt</th>\n",
       "      <td>0.991422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.988753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "sgd  0.988563\n",
       "dt   0.974647\n",
       "rf   0.991994\n",
       "xt   0.991422\n",
       "gb   0.988753"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "boosting_data = {\n",
    "    mod_name:\n",
    "    AdaBoostClassifier(base_estimator=mod_obj, n_estimators=ESTIMS, algorithm='SAMME')\n",
    "    .fit(X_train, y_train)\n",
    "    .score(X_test, y_test)    \n",
    "    for mod_name, mod_obj in base_learners\n",
    "}\n",
    "\n",
    "boosting_scores = pd.DataFrame.from_dict(data=boosting_data, orient='index')\n",
    "boosting_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.994560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.751006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.996032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xt</th>\n",
       "      <td>0.995540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.949299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "sgd  0.994560\n",
       "dt   0.751006\n",
       "rf   0.996032\n",
       "xt   0.995540\n",
       "gb   0.949299"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_roc_auc_data = {}\n",
    "for mod_name, mod_obj in base_learners:\n",
    "    boosting_model = AdaBoostClassifier(base_estimator=mod_obj, n_estimators=ESTIMS, algorithm='SAMME')\n",
    "    boosting_model.fit(X_train, y_train)\n",
    "    preds = boosting_model.predict(X_test)\n",
    "    score = roc_auc_score(preds, y_test)\n",
    "    boosting_roc_auc_data[mod_name] = score\n",
    "    \n",
    "boosting_roc_auc_scores = pd.DataFrame.from_dict(data=boosting_roc_auc_data, orient='index')\n",
    "boosting_roc_auc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Now create a visualization showing the performance of your supervised models on the test set, together with the unsupervised model. Has the performance improved after making use of the Class data? Which model obtains the best AUC?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
